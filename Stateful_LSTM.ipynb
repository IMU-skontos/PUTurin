{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Bidirectional, Dense, RepeatVector, TimeDistributed\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "        time  day  month  year   T_Supply   T_Return  SP_Return  T_Saturation  \\\n0      79200   14     10  2019  19.859999  20.469999       18.5     19.020000   \n1      80100   14     10  2019  19.855000  20.430000       18.5     19.020000   \n2      81000   14     10  2019  19.850000  20.410000       18.5     19.020000   \n3      81900   14     10  2019  19.840000  20.379999       18.5     19.080000   \n4      82800   14     10  2019  19.830000  20.350000       18.5     19.080000   \n...      ...  ...    ...   ...        ...        ...        ...           ...   \n33883  74700   14      4  2021  19.539999  20.004999       20.5     19.619999   \n33884  75600   14      4  2021  19.520000  19.949999       20.5     19.539999   \n33885  76500   14      4  2021  19.430000  19.955000       20.5     19.420000   \n33886  77400   14      4  2021  19.420000  19.920000       20.5     19.400000   \n33887  78300   14      4  2021  19.420000  19.900000       20.5     19.400000   \n\n       T_Outdoor  RH_Supply  RH_Return  RH_Outdoor  Energy  Power  \n0      20.299999  71.110001  58.919998        79.5     0.0    0.0  \n1      20.299999  71.320000  59.000000        82.0     0.0    0.0  \n2      20.299999  71.470001  59.109997        79.5     0.0    0.0  \n3      20.299999  71.439995  59.309998        77.0     0.0    0.0  \n4      20.299999  71.580002  59.559998        79.5     0.0    0.0  \n...          ...        ...        ...         ...     ...    ...  \n33883  14.700000  39.020000  27.930000        57.0     0.0    0.0  \n33884  13.700000  39.020000  28.090000        57.0     0.0    0.0  \n33885  13.700000  39.399998  27.930000        57.0     0.0    0.0  \n33886  13.700000  39.599998  28.039999        57.0     0.0    0.0  \n33887  13.700000  39.599998  28.150000        57.0     0.0    0.0  \n\n[33888 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>day</th>\n      <th>month</th>\n      <th>year</th>\n      <th>T_Supply</th>\n      <th>T_Return</th>\n      <th>SP_Return</th>\n      <th>T_Saturation</th>\n      <th>T_Outdoor</th>\n      <th>RH_Supply</th>\n      <th>RH_Return</th>\n      <th>RH_Outdoor</th>\n      <th>Energy</th>\n      <th>Power</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>79200</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.859999</td>\n      <td>20.469999</td>\n      <td>18.5</td>\n      <td>19.020000</td>\n      <td>20.299999</td>\n      <td>71.110001</td>\n      <td>58.919998</td>\n      <td>79.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80100</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.855000</td>\n      <td>20.430000</td>\n      <td>18.5</td>\n      <td>19.020000</td>\n      <td>20.299999</td>\n      <td>71.320000</td>\n      <td>59.000000</td>\n      <td>82.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>81000</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.850000</td>\n      <td>20.410000</td>\n      <td>18.5</td>\n      <td>19.020000</td>\n      <td>20.299999</td>\n      <td>71.470001</td>\n      <td>59.109997</td>\n      <td>79.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>81900</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.840000</td>\n      <td>20.379999</td>\n      <td>18.5</td>\n      <td>19.080000</td>\n      <td>20.299999</td>\n      <td>71.439995</td>\n      <td>59.309998</td>\n      <td>77.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>82800</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.830000</td>\n      <td>20.350000</td>\n      <td>18.5</td>\n      <td>19.080000</td>\n      <td>20.299999</td>\n      <td>71.580002</td>\n      <td>59.559998</td>\n      <td>79.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33883</th>\n      <td>74700</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.539999</td>\n      <td>20.004999</td>\n      <td>20.5</td>\n      <td>19.619999</td>\n      <td>14.700000</td>\n      <td>39.020000</td>\n      <td>27.930000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33884</th>\n      <td>75600</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.520000</td>\n      <td>19.949999</td>\n      <td>20.5</td>\n      <td>19.539999</td>\n      <td>13.700000</td>\n      <td>39.020000</td>\n      <td>28.090000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33885</th>\n      <td>76500</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.430000</td>\n      <td>19.955000</td>\n      <td>20.5</td>\n      <td>19.420000</td>\n      <td>13.700000</td>\n      <td>39.399998</td>\n      <td>27.930000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33886</th>\n      <td>77400</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.420000</td>\n      <td>19.920000</td>\n      <td>20.5</td>\n      <td>19.400000</td>\n      <td>13.700000</td>\n      <td>39.599998</td>\n      <td>28.039999</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33887</th>\n      <td>78300</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.420000</td>\n      <td>19.900000</td>\n      <td>20.5</td>\n      <td>19.400000</td>\n      <td>13.700000</td>\n      <td>39.599998</td>\n      <td>28.150000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>33888 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TurinAHU.csv')\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "\n",
    "# Extracting day, month, year, and time into separate columns\n",
    "df[\"day\"] = df[\"Timestamp\"].dt.day\n",
    "df[\"month\"] = df[\"Timestamp\"].dt.month\n",
    "df[\"year\"] = df[\"Timestamp\"].dt.year\n",
    "df[\"time\"] = df[\"Timestamp\"].dt.hour * 3600 + df[\"Timestamp\"].dt.minute * 60 + df[\"Timestamp\"].dt.second\n",
    "\n",
    "# Dropping the \"timestamp\" column\n",
    "df = df.drop(\"Timestamp\", axis=1)\n",
    "\n",
    "# Reordering the columns\n",
    "cols = df.columns.tolist()\n",
    "cols = [\"time\", \"day\", \"month\", \"year\"] + cols[:-4]\n",
    "df = df[cols]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (23653, 96, 1, 14)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm_23\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (96, 28)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[18], line 34\u001B[0m\n\u001B[0;32m     32\u001B[0m model\u001B[38;5;241m.\u001B[39madd(LSTM(\u001B[38;5;241m28\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtanh\u001B[39m\u001B[38;5;124m'\u001B[39m, dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, stateful\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, return_sequences\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[0;32m     33\u001B[0m model\u001B[38;5;241m.\u001B[39madd(LSTM(\u001B[38;5;241m28\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtanh\u001B[39m\u001B[38;5;124m'\u001B[39m, dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, stateful\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[1;32m---> 34\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mLSTM\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtanh\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdropout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstateful\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_sequences\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m model\u001B[38;5;241m.\u001B[39madd(LSTM(\u001B[38;5;241m28\u001B[39m, activation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtanh\u001B[39m\u001B[38;5;124m'\u001B[39m, dropout\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m, stateful\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, return_sequences\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[0;32m     36\u001B[0m model\u001B[38;5;241m.\u001B[39madd(RepeatVector(n_future))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\data_analytics\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001B[0m, in \u001B[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    203\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_setattr_tracking \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 205\u001B[0m   result \u001B[38;5;241m=\u001B[39m method(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    207\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_self_setattr_tracking \u001B[38;5;241m=\u001B[39m previous_value  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\data_analytics\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\data_analytics\\lib\\site-packages\\keras\\engine\\input_spec.py:232\u001B[0m, in \u001B[0;36massert_input_compatibility\u001B[1;34m(input_spec, inputs, layer_name)\u001B[0m\n\u001B[0;32m    230\u001B[0m     ndim \u001B[38;5;241m=\u001B[39m shape\u001B[38;5;241m.\u001B[39mrank\n\u001B[0;32m    231\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ndim \u001B[38;5;241m!=\u001B[39m spec\u001B[38;5;241m.\u001B[39mndim:\n\u001B[1;32m--> 232\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    233\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of layer \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    234\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis incompatible with the layer: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    235\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpected ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mspec\u001B[38;5;241m.\u001B[39mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, found ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    236\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFull shape received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtuple\u001B[39m(shape)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    237\u001B[0m         )\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec\u001B[38;5;241m.\u001B[39mmax_ndim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    239\u001B[0m     ndim \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;241m.\u001B[39mrank\n",
      "\u001B[1;31mValueError\u001B[0m: Input 0 of layer \"lstm_23\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (96, 28)"
     ]
    }
   ],
   "source": [
    "############################################################# STATEFUL LSTM #############################################################\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Prepare the data for training\n",
    "X = []\n",
    "y = []\n",
    "n_future = 2 # number of timesteps to predict\n",
    "n_past = 96 # number of timesteps to use as input\n",
    "batch_size = 96\n",
    "for i in range(n_past, len(data_scaled) - n_future + 1):\n",
    "    X.append(data_scaled[i - n_past:i, :])\n",
    "    y.append(data_scaled[i:i + n_future, :])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split_index = int(len(X) * 0.7)\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(14, batch_input_shape=(batch_size, X_train.shape[1], X_train.shape[2]), activation='tanh', stateful=True, return_sequences=True))\n",
    "model.add(LSTM(28, activation='tanh', dropout=0.5, stateful=True, return_sequences=True))\n",
    "model.add(LSTM(28, activation='tanh', dropout=0.5, stateful=True))\n",
    "model.add(RepeatVector(n_future))\n",
    "model.add(LSTM(28, activation='tanh', dropout=0.5, stateful=True, return_sequences=True))\n",
    "model.add(LSTM(28, activation='tanh', dropout=0.5, stateful=True, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(X_train.shape[2], activation='linear')))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "epochs = 500\n",
    "for i in range(epochs):\n",
    "    print('Epoch', i+1, '/', epochs)\n",
    "    history = model.fit(X_train, y_train, epochs=100, batch_size=batch_size, validation_split=0.2, shuffle=False)\n",
    "    model.reset_states()\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test, batch_size=batch_size)\n",
    "y_pred_rescaled = scaler.inverse_transform(y_pred.reshape(y_pred.shape[0]*y_pred.shape[1], y_pred.shape[2]))\n",
    "y_test_rescaled = scaler.inverse_transform(y_test.reshape(y_test.shape[0]*y_test.shape[1], y_test.shape[2]))\n",
    "\n",
    "mae = np.mean(np.abs(y_pred_rescaled - y_test_rescaled), axis=0)\n",
    "mape = np.mean(np.abs((y_pred_rescaled - y_test_rescaled) / y_test_rescaled), axis=0) * 100\n",
    "rmse = np.sqrt(np.mean(np.square(y_pred_rescaled - y_test_rescaled), axis=0))\n",
    "\n",
    "print('MAE:', mae)\n",
    "print('MAPE:', mape)\n",
    "print('RMSE:', rmse)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
