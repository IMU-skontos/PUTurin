{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, GRU, Bidirectional, Dense, RepeatVector, TimeDistributed\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "        time  day  month  year   T_Supply   T_Return  SP_Return  T_Saturation  \\\n0      79200   14     10  2019  19.859999  20.469999       18.5     19.020000   \n1      80100   14     10  2019  19.855000  20.430000       18.5     19.020000   \n2      81000   14     10  2019  19.850000  20.410000       18.5     19.020000   \n3      81900   14     10  2019  19.840000  20.379999       18.5     19.080000   \n4      82800   14     10  2019  19.830000  20.350000       18.5     19.080000   \n...      ...  ...    ...   ...        ...        ...        ...           ...   \n33883  74700   14      4  2021  19.539999  20.004999       20.5     19.619999   \n33884  75600   14      4  2021  19.520000  19.949999       20.5     19.539999   \n33885  76500   14      4  2021  19.430000  19.955000       20.5     19.420000   \n33886  77400   14      4  2021  19.420000  19.920000       20.5     19.400000   \n33887  78300   14      4  2021  19.420000  19.900000       20.5     19.400000   \n\n       T_Outdoor  RH_Supply  RH_Return  RH_Outdoor  Energy  Power  \n0      20.299999  71.110001  58.919998        79.5     0.0    0.0  \n1      20.299999  71.320000  59.000000        82.0     0.0    0.0  \n2      20.299999  71.470001  59.109997        79.5     0.0    0.0  \n3      20.299999  71.439995  59.309998        77.0     0.0    0.0  \n4      20.299999  71.580002  59.559998        79.5     0.0    0.0  \n...          ...        ...        ...         ...     ...    ...  \n33883  14.700000  39.020000  27.930000        57.0     0.0    0.0  \n33884  13.700000  39.020000  28.090000        57.0     0.0    0.0  \n33885  13.700000  39.399998  27.930000        57.0     0.0    0.0  \n33886  13.700000  39.599998  28.039999        57.0     0.0    0.0  \n33887  13.700000  39.599998  28.150000        57.0     0.0    0.0  \n\n[33888 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>day</th>\n      <th>month</th>\n      <th>year</th>\n      <th>T_Supply</th>\n      <th>T_Return</th>\n      <th>SP_Return</th>\n      <th>T_Saturation</th>\n      <th>T_Outdoor</th>\n      <th>RH_Supply</th>\n      <th>RH_Return</th>\n      <th>RH_Outdoor</th>\n      <th>Energy</th>\n      <th>Power</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>79200</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.859999</td>\n      <td>20.469999</td>\n      <td>18.5</td>\n      <td>19.020000</td>\n      <td>20.299999</td>\n      <td>71.110001</td>\n      <td>58.919998</td>\n      <td>79.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80100</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.855000</td>\n      <td>20.430000</td>\n      <td>18.5</td>\n      <td>19.020000</td>\n      <td>20.299999</td>\n      <td>71.320000</td>\n      <td>59.000000</td>\n      <td>82.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>81000</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.850000</td>\n      <td>20.410000</td>\n      <td>18.5</td>\n      <td>19.020000</td>\n      <td>20.299999</td>\n      <td>71.470001</td>\n      <td>59.109997</td>\n      <td>79.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>81900</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.840000</td>\n      <td>20.379999</td>\n      <td>18.5</td>\n      <td>19.080000</td>\n      <td>20.299999</td>\n      <td>71.439995</td>\n      <td>59.309998</td>\n      <td>77.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>82800</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.830000</td>\n      <td>20.350000</td>\n      <td>18.5</td>\n      <td>19.080000</td>\n      <td>20.299999</td>\n      <td>71.580002</td>\n      <td>59.559998</td>\n      <td>79.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33883</th>\n      <td>74700</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.539999</td>\n      <td>20.004999</td>\n      <td>20.5</td>\n      <td>19.619999</td>\n      <td>14.700000</td>\n      <td>39.020000</td>\n      <td>27.930000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33884</th>\n      <td>75600</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.520000</td>\n      <td>19.949999</td>\n      <td>20.5</td>\n      <td>19.539999</td>\n      <td>13.700000</td>\n      <td>39.020000</td>\n      <td>28.090000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33885</th>\n      <td>76500</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.430000</td>\n      <td>19.955000</td>\n      <td>20.5</td>\n      <td>19.420000</td>\n      <td>13.700000</td>\n      <td>39.399998</td>\n      <td>27.930000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33886</th>\n      <td>77400</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.420000</td>\n      <td>19.920000</td>\n      <td>20.5</td>\n      <td>19.400000</td>\n      <td>13.700000</td>\n      <td>39.599998</td>\n      <td>28.039999</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33887</th>\n      <td>78300</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.420000</td>\n      <td>19.900000</td>\n      <td>20.5</td>\n      <td>19.400000</td>\n      <td>13.700000</td>\n      <td>39.599998</td>\n      <td>28.150000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>33888 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TurinAHU.csv')\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "\n",
    "# Extracting day, month, year, and time into separate columns\n",
    "df[\"day\"] = df[\"Timestamp\"].dt.day\n",
    "df[\"month\"] = df[\"Timestamp\"].dt.month\n",
    "df[\"year\"] = df[\"Timestamp\"].dt.year\n",
    "df[\"time\"] = df[\"Timestamp\"].dt.hour * 3600 + df[\"Timestamp\"].dt.minute * 60 + df[\"Timestamp\"].dt.second\n",
    "\n",
    "# Dropping the \"timestamp\" column\n",
    "df = df.drop(\"Timestamp\", axis=1)\n",
    "\n",
    "# Reordering the columns\n",
    "cols = df.columns.tolist()\n",
    "cols = [\"time\", \"day\", \"month\", \"year\"] + cols[:-4]\n",
    "df = df[cols]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "198/198 [==============================] - 24s 91ms/step - loss: 0.0677 - val_loss: 0.0255\n",
      "Epoch 2/100\n",
      "198/198 [==============================] - 16s 79ms/step - loss: 0.0225 - val_loss: 0.0151\n",
      "Epoch 3/100\n",
      "198/198 [==============================] - 16s 80ms/step - loss: 0.0168 - val_loss: 0.0126\n",
      "Epoch 4/100\n",
      "198/198 [==============================] - 16s 80ms/step - loss: 0.0145 - val_loss: 0.0108\n",
      "Epoch 5/100\n",
      "198/198 [==============================] - 17s 84ms/step - loss: 0.0129 - val_loss: 0.0099\n",
      "Epoch 6/100\n",
      "198/198 [==============================] - 17s 85ms/step - loss: 0.0120 - val_loss: 0.0089\n",
      "Epoch 7/100\n",
      "198/198 [==============================] - 17s 84ms/step - loss: 0.0112 - val_loss: 0.0083\n",
      "Epoch 8/100\n",
      "198/198 [==============================] - 19s 98ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 9/100\n",
      "198/198 [==============================] - 18s 90ms/step - loss: 0.0100 - val_loss: 0.0073\n",
      "Epoch 10/100\n",
      "198/198 [==============================] - 21s 107ms/step - loss: 0.0095 - val_loss: 0.0072\n",
      "Epoch 11/100\n",
      "198/198 [==============================] - 19s 96ms/step - loss: 0.0091 - val_loss: 0.0069\n",
      "Epoch 12/100\n",
      "198/198 [==============================] - 19s 95ms/step - loss: 0.0088 - val_loss: 0.0065\n",
      "Epoch 13/100\n",
      "198/198 [==============================] - 17s 85ms/step - loss: 0.0084 - val_loss: 0.0063\n",
      "Epoch 14/100\n",
      "198/198 [==============================] - 17s 87ms/step - loss: 0.0082 - val_loss: 0.0061\n",
      "Epoch 15/100\n",
      "198/198 [==============================] - 20s 100ms/step - loss: 0.0079 - val_loss: 0.0057\n",
      "Epoch 16/100\n",
      "198/198 [==============================] - 20s 101ms/step - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 17/100\n",
      "198/198 [==============================] - 17s 87ms/step - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 18/100\n",
      "198/198 [==============================] - 18s 92ms/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 19/100\n",
      "198/198 [==============================] - 19s 95ms/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 20/100\n",
      "198/198 [==============================] - 17s 86ms/step - loss: 0.0070 - val_loss: 0.0051\n",
      "Epoch 21/100\n",
      "198/198 [==============================] - 17s 86ms/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 22/100\n",
      "198/198 [==============================] - 17s 86ms/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 23/100\n",
      "198/198 [==============================] - 17s 85ms/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 24/100\n",
      "198/198 [==============================] - 17s 86ms/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 25/100\n",
      "198/198 [==============================] - 17s 86ms/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 26/100\n",
      "198/198 [==============================] - 17s 86ms/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 27/100\n",
      "198/198 [==============================] - 17s 86ms/step - loss: 0.0061 - val_loss: 0.0045\n",
      "Epoch 28/100\n",
      "198/198 [==============================] - 17s 86ms/step - loss: 0.0060 - val_loss: 0.0044\n",
      "Epoch 29/100\n",
      "198/198 [==============================] - 17s 86ms/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Epoch 30/100\n",
      "198/198 [==============================] - 20s 100ms/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 31/100\n",
      "198/198 [==============================] - 18s 90ms/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 32/100\n",
      "198/198 [==============================] - 18s 90ms/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 33/100\n",
      "198/198 [==============================] - 18s 91ms/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 34/100\n",
      "198/198 [==============================] - 18s 92ms/step - loss: 0.0057 - val_loss: 0.0043\n",
      "Epoch 35/100\n",
      "198/198 [==============================] - 18s 92ms/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 36/100\n",
      "198/198 [==============================] - 18s 91ms/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 37/100\n",
      "198/198 [==============================] - 20s 101ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 38/100\n",
      "198/198 [==============================] - 18s 90ms/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 39/100\n",
      "198/198 [==============================] - 18s 91ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 40/100\n",
      "198/198 [==============================] - 18s 93ms/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 41/100\n",
      "198/198 [==============================] - 20s 102ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 42/100\n",
      "198/198 [==============================] - 19s 94ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 43/100\n",
      "198/198 [==============================] - 18s 90ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 44/100\n",
      "198/198 [==============================] - 18s 92ms/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 45/100\n",
      "198/198 [==============================] - 18s 91ms/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 46/100\n",
      "198/198 [==============================] - 18s 93ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 47/100\n",
      "198/198 [==============================] - 18s 93ms/step - loss: 0.0050 - val_loss: 0.0040\n",
      "Epoch 48/100\n",
      "198/198 [==============================] - 18s 92ms/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 49/100\n",
      "198/198 [==============================] - 18s 92ms/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 50/100\n",
      "198/198 [==============================] - 18s 92ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 51/100\n",
      "198/198 [==============================] - 19s 95ms/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 52/100\n",
      "198/198 [==============================] - 17s 87ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 53/100\n",
      "198/198 [==============================] - 17s 87ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 54/100\n",
      "198/198 [==============================] - 23s 114ms/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 55/100\n",
      "198/198 [==============================] - 17s 85ms/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 56/100\n",
      "198/198 [==============================] - 16s 83ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 57/100\n",
      "198/198 [==============================] - 19s 98ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 58/100\n",
      "198/198 [==============================] - 19s 94ms/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 59/100\n",
      "198/198 [==============================] - 20s 101ms/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 60/100\n",
      "198/198 [==============================] - 19s 97ms/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 61/100\n",
      "198/198 [==============================] - 18s 90ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 62/100\n",
      "198/198 [==============================] - 21s 107ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 63/100\n",
      "198/198 [==============================] - 18s 90ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 64/100\n",
      "198/198 [==============================] - 18s 91ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 65/100\n",
      "198/198 [==============================] - 20s 99ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 66/100\n",
      "198/198 [==============================] - 19s 95ms/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 67/100\n",
      "198/198 [==============================] - 18s 92ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 68/100\n",
      "198/198 [==============================] - 20s 102ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 69/100\n",
      "198/198 [==============================] - 18s 91ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 70/100\n",
      "198/198 [==============================] - 20s 102ms/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 71/100\n",
      "198/198 [==============================] - 22s 109ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 72/100\n",
      "198/198 [==============================] - 18s 93ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 73/100\n",
      "198/198 [==============================] - 20s 99ms/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 74/100\n",
      "198/198 [==============================] - 20s 101ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 75/100\n",
      "198/198 [==============================] - 19s 97ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 76/100\n",
      "198/198 [==============================] - 20s 99ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 77/100\n",
      "198/198 [==============================] - 20s 101ms/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 78/100\n",
      "198/198 [==============================] - 19s 98ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 79/100\n",
      "198/198 [==============================] - 19s 95ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 80/100\n",
      "198/198 [==============================] - 19s 98ms/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 81/100\n",
      "198/198 [==============================] - 19s 96ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 82/100\n",
      "198/198 [==============================] - 18s 93ms/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 83/100\n",
      "198/198 [==============================] - 21s 105ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 84/100\n",
      "198/198 [==============================] - 19s 99ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 85/100\n",
      "198/198 [==============================] - 21s 105ms/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 86/100\n",
      "198/198 [==============================] - 19s 98ms/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 87/100\n",
      "198/198 [==============================] - 18s 89ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 88/100\n",
      "198/198 [==============================] - 19s 95ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 89/100\n",
      "198/198 [==============================] - 18s 93ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 90/100\n",
      "198/198 [==============================] - 20s 99ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 91/100\n",
      "198/198 [==============================] - 18s 90ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 92/100\n",
      "198/198 [==============================] - 18s 89ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 93/100\n",
      "198/198 [==============================] - 18s 90ms/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Epoch 94/100\n",
      "198/198 [==============================] - 18s 92ms/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 95/100\n",
      "198/198 [==============================] - 18s 93ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 96/100\n",
      "198/198 [==============================] - 19s 94ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 97/100\n",
      "198/198 [==============================] - 18s 93ms/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 98/100\n",
      "198/198 [==============================] - 18s 93ms/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 99/100\n",
      "198/198 [==============================] - 18s 91ms/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 100/100\n",
      "198/198 [==============================] - 17s 87ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "317/317 [==============================] - 6s 13ms/step\n",
      "MAE: [2.20577453e+03 9.14183353e-01 2.47568272e-01 1.68069677e-02\n",
      " 6.29084663e-01 3.79379648e-01 1.05352253e-01 4.39613852e-01\n",
      " 1.08093980e+00 1.57069035e+00 1.51765765e+00 4.19334046e+00\n",
      " 5.30063630e-01 1.72285034e-01]\n",
      "MAPE: [           inf 1.50485998e+01 8.29461813e+00 8.32040629e-04\n",
      " 3.04616243e+00 1.91578726e+00 4.76297910e-01 2.38872058e+00\n",
      " 1.01302186e+01 3.64782967e+00 4.38599751e+00 7.13462761e+00\n",
      "            inf            inf]\n",
      "RMSE: [6.65055423e+03 1.47401116e+00 4.00109654e-01 3.10776076e-02\n",
      " 9.61319342e-01 5.31217962e-01 1.96280610e-01 6.29927960e-01\n",
      " 1.39052306e+00 2.13112425e+00 1.98024445e+00 5.65255475e+00\n",
      " 1.31642599e+00 5.66008727e-01]\n"
     ]
    }
   ],
   "source": [
    "############################################################# STATELESS LSTM #############################################################\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Prepare the data for training\n",
    "X = []\n",
    "y = []\n",
    "n_future = 2 # number of timesteps to predict\n",
    "n_past = 96 # number of timesteps to use as input\n",
    "for i in range(n_past, len(data_scaled) - n_future + 1):\n",
    "    X.append(data_scaled[i - n_past:i, :])\n",
    "    y.append(data_scaled[i:i + n_future, :])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(LSTM(14, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(28, activation='tanh', dropout=0.5, return_sequences=True))\n",
    "model.add(LSTM(28, activation='tanh', dropout=0.5))\n",
    "model.add(RepeatVector(n_future))\n",
    "#model.add(LSTM(28, activation='tanh', dropout=0.5, return_sequences=True))\n",
    "#model.add(LSTM(28, activation='tanh', dropout=0.5, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(X_train.shape[2], activation='linear')))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=96, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_rescaled = scaler.inverse_transform(y_pred.reshape(y_pred.shape[0]*y_pred.shape[1], y_pred.shape[2]))\n",
    "y_test_rescaled = scaler.inverse_transform(y_test.reshape(y_test.shape[0]*y_test.shape[1], y_test.shape[2]))\n",
    "\n",
    "mae = np.mean(np.abs(y_pred_rescaled - y_test_rescaled), axis=0)\n",
    "mape = np.mean(np.abs((y_pred_rescaled - y_test_rescaled) / y_test_rescaled), axis=0) * 100\n",
    "rmse = np.sqrt(np.mean(np.square(y_pred_rescaled - y_test_rescaled), axis=0))\n",
    "\n",
    "print('MAE:', mae)\n",
    "print('MAPE:', mape)\n",
    "print('RMSE:', rmse)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
