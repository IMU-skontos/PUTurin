{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-25T19:39:15.186461Z",
     "start_time": "2023-05-25T19:39:15.182222Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import autokeras as ak\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "        time  day  month  year   T_Supply   T_Return  SP_Return  T_Saturation   \n0      79200   14     10  2019  19.859999  20.469999       18.5     19.020000  \\\n1      80100   14     10  2019  19.855000  20.430000       18.5     19.020000   \n2      81000   14     10  2019  19.850000  20.410000       18.5     19.020000   \n3      81900   14     10  2019  19.840000  20.379999       18.5     19.080000   \n4      82800   14     10  2019  19.830000  20.350000       18.5     19.080000   \n...      ...  ...    ...   ...        ...        ...        ...           ...   \n33883  74700   14      4  2021  19.539999  20.004999       20.5     19.619999   \n33884  75600   14      4  2021  19.520000  19.949999       20.5     19.539999   \n33885  76500   14      4  2021  19.430000  19.955000       20.5     19.420000   \n33886  77400   14      4  2021  19.420000  19.920000       20.5     19.400000   \n33887  78300   14      4  2021  19.420000  19.900000       20.5     19.400000   \n\n       T_Outdoor  RH_Supply  RH_Return  RH_Outdoor  Energy  Power  \n0      20.299999  71.110001  58.919998        79.5     0.0    0.0  \n1      20.299999  71.320000  59.000000        82.0     0.0    0.0  \n2      20.299999  71.470001  59.109997        79.5     0.0    0.0  \n3      20.299999  71.439995  59.309998        77.0     0.0    0.0  \n4      20.299999  71.580002  59.559998        79.5     0.0    0.0  \n...          ...        ...        ...         ...     ...    ...  \n33883  14.700000  39.020000  27.930000        57.0     0.0    0.0  \n33884  13.700000  39.020000  28.090000        57.0     0.0    0.0  \n33885  13.700000  39.399998  27.930000        57.0     0.0    0.0  \n33886  13.700000  39.599998  28.039999        57.0     0.0    0.0  \n33887  13.700000  39.599998  28.150000        57.0     0.0    0.0  \n\n[33888 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>day</th>\n      <th>month</th>\n      <th>year</th>\n      <th>T_Supply</th>\n      <th>T_Return</th>\n      <th>SP_Return</th>\n      <th>T_Saturation</th>\n      <th>T_Outdoor</th>\n      <th>RH_Supply</th>\n      <th>RH_Return</th>\n      <th>RH_Outdoor</th>\n      <th>Energy</th>\n      <th>Power</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>79200</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.859999</td>\n      <td>20.469999</td>\n      <td>18.5</td>\n      <td>19.020000</td>\n      <td>20.299999</td>\n      <td>71.110001</td>\n      <td>58.919998</td>\n      <td>79.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>80100</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.855000</td>\n      <td>20.430000</td>\n      <td>18.5</td>\n      <td>19.020000</td>\n      <td>20.299999</td>\n      <td>71.320000</td>\n      <td>59.000000</td>\n      <td>82.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>81000</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.850000</td>\n      <td>20.410000</td>\n      <td>18.5</td>\n      <td>19.020000</td>\n      <td>20.299999</td>\n      <td>71.470001</td>\n      <td>59.109997</td>\n      <td>79.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>81900</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.840000</td>\n      <td>20.379999</td>\n      <td>18.5</td>\n      <td>19.080000</td>\n      <td>20.299999</td>\n      <td>71.439995</td>\n      <td>59.309998</td>\n      <td>77.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>82800</td>\n      <td>14</td>\n      <td>10</td>\n      <td>2019</td>\n      <td>19.830000</td>\n      <td>20.350000</td>\n      <td>18.5</td>\n      <td>19.080000</td>\n      <td>20.299999</td>\n      <td>71.580002</td>\n      <td>59.559998</td>\n      <td>79.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>33883</th>\n      <td>74700</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.539999</td>\n      <td>20.004999</td>\n      <td>20.5</td>\n      <td>19.619999</td>\n      <td>14.700000</td>\n      <td>39.020000</td>\n      <td>27.930000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33884</th>\n      <td>75600</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.520000</td>\n      <td>19.949999</td>\n      <td>20.5</td>\n      <td>19.539999</td>\n      <td>13.700000</td>\n      <td>39.020000</td>\n      <td>28.090000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33885</th>\n      <td>76500</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.430000</td>\n      <td>19.955000</td>\n      <td>20.5</td>\n      <td>19.420000</td>\n      <td>13.700000</td>\n      <td>39.399998</td>\n      <td>27.930000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33886</th>\n      <td>77400</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.420000</td>\n      <td>19.920000</td>\n      <td>20.5</td>\n      <td>19.400000</td>\n      <td>13.700000</td>\n      <td>39.599998</td>\n      <td>28.039999</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>33887</th>\n      <td>78300</td>\n      <td>14</td>\n      <td>4</td>\n      <td>2021</td>\n      <td>19.420000</td>\n      <td>19.900000</td>\n      <td>20.5</td>\n      <td>19.400000</td>\n      <td>13.700000</td>\n      <td>39.599998</td>\n      <td>28.150000</td>\n      <td>57.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>33888 rows Ã— 14 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('TurinAHU.csv')\n",
    "df[\"Timestamp\"] = pd.to_datetime(df[\"Timestamp\"])\n",
    "\n",
    "# Extracting day, month, year, and time into separate columns\n",
    "df[\"day\"] = df[\"Timestamp\"].dt.day\n",
    "df[\"month\"] = df[\"Timestamp\"].dt.month\n",
    "df[\"year\"] = df[\"Timestamp\"].dt.year\n",
    "df[\"time\"] = df[\"Timestamp\"].dt.hour * 3600 + df[\"Timestamp\"].dt.minute * 60 + df[\"Timestamp\"].dt.second\n",
    "\n",
    "# Dropping the \"timestamp\" column\n",
    "df = df.drop(\"Timestamp\", axis=1)\n",
    "\n",
    "# Reordering the columns\n",
    "cols = df.columns.tolist()\n",
    "cols = [\"time\", \"day\", \"month\", \"year\"] + cols[:-4]\n",
    "df = df[cols]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T19:39:15.253116Z",
     "start_time": "2023-05-25T19:39:15.190751Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "\n",
    "X = df[['time', 'day', 'month', 'year']]\n",
    "y = df.drop(columns=['time', 'day', 'month', 'year'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T19:39:15.263334Z",
     "start_time": "2023-05-25T19:39:15.255205Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [40]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Initialize and train the AutoKeras model\u001B[39;00m\n\u001B[1;32m      2\u001B[0m regressor \u001B[38;5;241m=\u001B[39m ak\u001B[38;5;241m.\u001B[39mStructuredDataRegressor(max_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, overwrite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mregressor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Evaluate the model on the testing set\u001B[39;00m\n\u001B[1;32m      6\u001B[0m mse \u001B[38;5;241m=\u001B[39m mean_squared_error(y_test, regressor\u001B[38;5;241m.\u001B[39mpredict(X_test))\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/data_analytics/lib/python3.8/site-packages/autokeras/tasks/structured_data.py:139\u001B[0m, in \u001B[0;36mBaseStructuredDataPipeline.fit\u001B[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001B[0m\n\u001B[1;32m    135\u001B[0m         validation_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_read_from_csv(x_val, y_val)\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_in_fit(x)\n\u001B[0;32m--> 139\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_split\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m history\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/data_analytics/lib/python3.8/site-packages/autokeras/auto_model.py:280\u001B[0m, in \u001B[0;36mAutoModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validation_data:\n\u001B[1;32m    278\u001B[0m     validation_split \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m--> 280\u001B[0m dataset, validation_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_convert_to_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_analyze_data(dataset)\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_hyper_pipeline(dataset)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/data_analytics/lib/python3.8/site-packages/autokeras/auto_model.py:398\u001B[0m, in \u001B[0;36mAutoModel._convert_to_dataset\u001B[0;34m(self, x, y, validation_data, batch_size)\u001B[0m\n\u001B[1;32m    396\u001B[0m     x \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x, y: x)\n\u001B[1;32m    397\u001B[0m     y \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x, y: y)\n\u001B[0;32m--> 398\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_adapt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    399\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_adapt(y, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_heads, batch_size)\n\u001B[1;32m    400\u001B[0m dataset \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mzip((x, y))\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/data_analytics/lib/python3.8/site-packages/autokeras/auto_model.py:311\u001B[0m, in \u001B[0;36mAutoModel._adapt\u001B[0;34m(self, dataset, hms, batch_size)\u001B[0m\n\u001B[1;32m    309\u001B[0m adapted \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m source, hm \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sources, hms):\n\u001B[0;32m--> 311\u001B[0m     source \u001B[38;5;241m=\u001B[39m \u001B[43mhm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_adapter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madapt\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    312\u001B[0m     adapted\u001B[38;5;241m.\u001B[39mappend(source)\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(adapted) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/data_analytics/lib/python3.8/site-packages/autokeras/engine/adapter.py:68\u001B[0m, in \u001B[0;36mAdapter.adapt\u001B[0;34m(self, dataset, batch_size)\u001B[0m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Check, convert and batch the dataset.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \n\u001B[1;32m     59\u001B[0m \u001B[38;5;124;03m# Arguments\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    tf.data.Dataset. The converted dataset.\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck(dataset)\n\u001B[0;32m---> 68\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_to_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m dataset\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/data_analytics/lib/python3.8/site-packages/autokeras/adapters/input_adapters.py:73\u001B[0m, in \u001B[0;36mStructuredDataAdapter.convert_to_dataset\u001B[0;34m(self, dataset, batch_size)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dataset, pd\u001B[38;5;241m.\u001B[39mDataFrame):\n\u001B[1;32m     72\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m---> 73\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dataset, np\u001B[38;5;241m.\u001B[39mndarray) \u001B[38;5;129;01mand\u001B[39;00m dataset\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobject\u001B[49m:\n\u001B[1;32m     74\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39municode)\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mconvert_to_dataset(dataset, batch_size)\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/data_analytics/lib/python3.8/site-packages/numpy/__init__.py:305\u001B[0m, in \u001B[0;36m__getattr__\u001B[0;34m(attr)\u001B[0m\n\u001B[1;32m    300\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    301\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIn the future `np.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mattr\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` will be defined as the \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    302\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcorresponding NumPy scalar.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;167;01mFutureWarning\u001B[39;00m, stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    304\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;129;01min\u001B[39;00m __former_attrs__:\n\u001B[0;32m--> 305\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(__former_attrs__[attr])\n\u001B[1;32m    307\u001B[0m \u001B[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001B[39;00m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001B[39;00m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m    311\u001B[0m \u001B[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001B[39;00m\n\u001B[1;32m    312\u001B[0m \u001B[38;5;66;03m# the full `numpy.testing` namespace\u001B[39;00m\n\u001B[1;32m    313\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attr \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtesting\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# Initialize and train the AutoKeras model\n",
    "regressor = ak.StructuredDataRegressor(max_trials=10, overwrite=True)\n",
    "regressor.fit(X_train, y_train, verbose=2)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "mse = mean_squared_error(y_test, regressor.predict(X_test))\n",
    "mae = mean_absolute_error(y_test, regressor.predict(X_test))\n",
    "mape = mean_absolute_percentage_error(y_test, regressor.predict(X_test))\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean Squared Error:', mse)\n",
    "print('Mean Absolute Error:', mae)\n",
    "print('Mean Absolute Percentage Error:', mape)\n",
    "print('Root Mean Squared Error:', rmse)\n",
    "\n",
    "# Make predictions\n",
    "predictions = regressor.predict(X_test)\n",
    "\n",
    "# Get predictions for the next 2 timesteps\n",
    "next_timestep_predictions = regressor.predict(X_test, return_pred_sequences=True)[:, -2:, :]\n",
    "\n",
    "# Print the predicted values for the next 2 timesteps\n",
    "print('Predicted values for the next 2 timesteps:')\n",
    "print(next_timestep_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-25T19:39:15.309535Z",
     "start_time": "2023-05-25T19:39:15.266295Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
